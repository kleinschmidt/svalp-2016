---
author: "Dave F. Kleinschmidt and T. Florian Jaeger"
title: "What do you expect from an unfamiliar talker?"
output: 
  revealjs::revealjs_presentation:
    template: slides_template.html
    self_contained: false
    keep_md: true
    transition: none
    background_transition: none
    css: slides.css
    reveal_options:
      center: true
      history: true
      notes: true

---


```{r preamble, message = FALSE, warning = FALSE, error = FALSE, results='hide', echo=FALSE}

library(knitr)

opts_chunk$set(dev = 'png',
               fig.retina = 2,
               error = FALSE, warning = FALSE, message = FALSE,
               results = 'hide', echo = FALSE,
               cache = TRUE)

library(dplyr)
library(tidyr)
library(magrittr)
library(ggplot2)
library(assertthat)
library(gganimate)
library(animation)
ani.options(autobrowse = FALSE, interval = .2)

## FRom the gganimate github readme: a hacked-together gif animation hook:
## https://github.com/dgrtwo/gganimate/blob/master/README.Rmd

opts_knit$set(animation.fun = function(x, options, format = "gif") {
  x = c(knitr:::sans_ext(x), knitr:::file_ext(x))
  fig.num = options$fig.num
  format = sub("^[.]", "", format)
  fig.fname = paste0(sub(paste0(fig.num, "$"), "*", x[1]), 
                     ".", x[2])
  mov.fname = paste0(sub(paste0(fig.num, "$"), "", x[1]), ".", 
                     format)

  # order correctly
  figs <- Sys.glob(fig.fname)
  figs <- figs[order(as.numeric(stringr::str_match(figs, paste0("(\\d+)\\.", x[2]))[, 2]))]

  animation::im.convert(figs, output = mov.fname)
  
  sprintf("![%s](%s)", options$label, paste0(opts_knit$get("base.url"), mov.fname))
})

## force png and fig.retina=1 for fig.show='animate'
opts_hooks$set(fig.show = function(options) {
  if (options$fig.show == 'animate') {
    options$dev <- 'png'
    options$fig.retina <- 1
  }
  options
})



theme_set(theme_bw() +
            theme(panel.border = element_blank())
          )

## data and helper functions
## devtools::install_github('kleinschmidt/phonetic-sup-unsup')
require(supunsup)

data <- supunsup::supunsup_clean %>%
  filter(supCond == 'unsupervised') %>%
  mutate(trueCat = respCategory,
         subjNum = as.numeric(factor(subject)),
         trueCatNum = as.numeric(trueCat),
         respCatNum = as.numeric(respCat))

data_by_subject <- data %>%
  group_by(subject, bvotCond, vot) %>%
  summarise(prob_p = mean(respP))

# correspondence between subject ids and numbers from model
subjects <-
  data %>%
  mutate(subject_num = as.numeric(factor(subject))) %>%
  group_by(subject, bvotCond, subject_num) %>%
  summarise() %>%
  arrange(subject_num)


prior_stats <- supunsup::prior_stats %>%
  filter(source == 'kronrod2012')

exposure_stats <- data %>%
  group_by(bvotCond, category=trueCat) %>%
  summarise(mean=mean(vot), sd=sd(vot))

sd_noise = sqrt(82)

stats_to_lhood <- function(stats, noise_sd=sd_noise, xlim=c(-30, 90)) {
  stats %>%
    group_by(category, mean, sd) %>%
    do(data.frame(vot=seq(xlim[1], xlim[2], 0.5))) %>%
    ungroup() %>%
    mutate(lhood = dnorm(vot, mean, sqrt(sd^2 + noise_sd^2))) %>%
    select(-mean, -sd)
}


```

# Introduction

## Questions

> 1. Is rapid adaptation to an unfamiliar talker __constrained__?
> 2. Are constraints consistent with listeners starting from a __single set of prior beliefs__?
> 3. Do these inferred prior beliefs reflect __talker variation__?

# Experiment

## {data-background-video="demo_trials.mov"}

<!--SO first I want to show you what the paradigm looks like. hear a word, click on matching picture. all the words are b/p minimal pairs, so voicing is the only thing to distinguish them. -->

---

<!-- unbeknownst to the listener, we're sampling a VOT randomly on every trial, from a bimodal distribution.  -->

VOT drawn from a __bimodal distribution__

```{r one-sub}

one_sub <- data %>%
  filter(bvotCond == -10) %>%
  filter(subject == first(subject)) %>%
  select(bvotCond, respP, trial, vot)

```

```{r exposure-build-up, fig.show='animate', fig.width=6.5, fig.height=4.5, dependson='one-sub'}

## Show exposure building up...

one_sub  %>%
  arrange(trial) %>%
  mutate(trials_tenths = ntile(trial, 10),
         trials_ten = floor(trial/10)*10,
         trials_frame = ifelse(trial < 20, trial, trials_ten)) %>%
  ggplot(aes(x=vot, group=trials_frame,
             fill = bvotCond, color = bvotCond,
             frame=trials_frame, cumulative=TRUE)) +
  geom_bar(binwidth=10) +
  geom_point(aes(y=-5), position=position_jitter(w=5, h=5), alpha=0.5) +
  scale_x_continuous('VOT (ms)', breaks = seq(-20, 60, by=20)) +
  scale_y_continuous('Count') + 
  scale_fill_discrete(drop=FALSE) +
  scale_color_discrete(drop=FALSE) +
  theme(legend.position='none') ->
  p

gg_animate(p)

```

```{r class-fun-build-up, fig.show='animate', eval=FALSE}

one_sub %>%
  group_by(vot, trials_ten) %>%
  summarise(respP = sum(respP),
            n_trial = n()) %>%
  group_by(vot) %>%
  arrange(trials_ten) %>%
  mutate(respP = cumsum(respP),
         n_trial = cumsum(n_trial),
         prop_p = respP / n_trial)

## ## And at the same time, classification function building up
## ggplot(one_sub, aes(x=vot, y=respP, group=trials_ten,
##                     frame=trials_ten)) +
##   geom_point(aes(cumulative=TRUE), position=position_jitter(h=0.1, w=5)) +
##   geom_line(stat='summary', fun.y=mean) ->
##   p

## gg_animate(p)

```



## Distributional learning

```{r dist-learning-schematic, fig.width=3, fig.height=3, out.width="33%", dependson='one-sub'}

one_sub %>%
  ggplot(aes(x=factor(vot), fill=bvotCond)) +
  geom_bar(stat='count', show.legend=FALSE) +
  labs(x = 'VOT (ms)', y='') +
  scale_fill_discrete(drop = FALSE) +
  ggtitle('1. Exposure distribution')


lhood_to_classification <- function(lhood) {
  lhood %>%
    spread(category, lhood) %>%
    mutate(prob_p = p / (p+b))
}

exposure_stats %>%
  semi_join(one_sub) %>%
  group_by(bvotCond) %>%
  do({stats_to_lhood(., noise_sd=0)}) %>%
  lhood_to_classification() %>%
  ggplot(aes(x=vot, y=prob_p, color=bvotCond)) +
  geom_line(size=1, linetype=2) +
  theme(legend.position = 'none') + 
  scale_x_continuous('VOT (ms)', breaks = seq(-100, 100, by=20),
                     limits = range(one_sub$vot)) + 
  labs(y = 'Probability /p/ response') +
  scale_color_discrete(drop = FALSE) + 
  ggtitle('2. Predict classification') ->
  p

print(p)

p <- p +
  geom_point(data=one_sub,
             aes(x=vot, y=respP),
             stat='summary', fun.y=mean)

## print(p)

p <- p +
  geom_line(stat='smooth', method = 'glm', method.args = list(family='binomial'),
            data=one_sub,
            aes(x=vot, y=respP),
            size = 0.5) +
  ggtitle('3. Measure and compare')

print(p)

```

## Design

```{r distributions, fig.width=8, fig.height=2, out.width='100%'}

## prior_stats <- data.frame(category=factor(c('b', 'p')),
##                           mean = c(0, 60),
##                           sd = sqrt(c(14, 254)))

exposure_lhood <- exposure_stats %>%
  group_by(bvotCond) %>%
  do(stats_to_lhood(., sd_noise))

prior_lhood <- prior_stats %>% stats_to_lhood(sd_noise)

data %>%
  group_by(bvotCond, vot) %>%
  filter(subject == first(subject)) %>%
  tally() %>%
  ggplot(aes(x=vot)) +
  geom_bar(stat='identity', aes(y=n, fill=bvotCond)) +
  geom_line(data=prior_lhood, aes(y=lhood*1600, group=category),
            color="black", linetype=2) +
  geom_text(data=data.frame(bvotCond=-10), x = 10, y = 60,
            label = 'Typical Talker',
            color='black', hjust=0, vjust=0.3, size=3) +
  geom_text(data=data.frame(bvotCond=-10), x = 40, y = 50,
            label = 'Exposure\nTalker',
            color=hcl(h=15, c=100, l=65), hjust=0, vjust=0.8, size=3,
            lineheight=1) + 
  facet_grid(.~bvotCond) +
  scale_x_continuous('VOT (ms)') +
  scale_y_continuous('Frequency') +
  scale_fill_discrete('/b/ mean\nVOT') +
  theme(legend.position='none')

```

* Five "accents" with different VOT distributions
* $n=`r data %$% subject %>% n_distinct()`$ subjects on Mechanical Turk
* 222 trials (about 20 minutes)


## Results: classification

```{r class-fcns, fig.width=8, fig.height=2, out.width="100%"}

lhood_to_classification <- function(lhood) {
  lhood %>%
    spread(category, lhood) %>%
    mutate(prob_p = p / (p+b))
}

perfect_learning <- exposure_stats %>%
  group_by(bvotCond) %>%
  do(stats_to_lhood(.)) %>%
  lhood_to_classification

no_learning <- prior_stats %>%
  stats_to_lhood %>%
  lhood_to_classification

prior_bound <- no_learning %>%
  arrange(abs(prob_p - 0.5)) %>%
  filter(row_number() ==1) %$%
  vot


boundaries <- data %>%
  group_by(bvotCond, subject) %>%
  do({ glm(respP ~ vot, family='binomial', data=.) %>%
         broom::tidy() %>%
         select(term, estimate)
  }) %>%
  ungroup() %>%
  spread(term, estimate) %>%
  mutate(boundary = -`(Intercept)` / vot,
         ideal_boundary = as.numeric(as.character(bvotCond)) + 20,
         prior_boundary = prior_bound,
         prop_shift = (boundary-prior_boundary)/(ideal_boundary-prior_boundary))

boundary_summary <- boundaries %>%
  group_by(bvotCond) %>%
  summarise(median_shift_perc = round(100*median(prop_shift)),
            shift_text = paste(median_shift_perc, '%', sep='')) %>%
  filter(bvotCond != 0)                 # basically no shift possible


ggplot(data, aes(x=vot, y=respP, color=bvotCond)) +
  geom_line(aes(group=subject), stat='smooth', 
            method='glm', method.args=list(family='binomial'),
            alpha=0.2) +
  facet_grid(.~bvotCond) +
  geom_line(data=perfect_learning, aes(y=prob_p), group=1, linetype=2, size=1) +
  geom_line(data=no_learning, aes(y=prob_p), group=1, linetype=2, color='black') +
  geom_text(data=data.frame(bvotCond=-10),
            x = 30, y = 0, label = 'Typical\ntalker',
            size = 3.5, hjust=0, vjust = 0, color='black',
            lineheight=1) + 
  geom_text(data=data.frame(bvotCond=-10),
            x = 12, y = 1, label = 'Expo-\nsure',
            size = 3.5, hjust=1, vjust=1, color=hcl(15, c=100, l=65),
            lineheight=1, fontface='bold') + 
  geom_text(data=data.frame(bvotCond=-10),
            x = 90, y = 0.75, label = 'Actual\nlisteners',
            size = 3.5, hjust=1, vjust=1, color=hcl(15, c=100, l=65),
            lineheight=1) + 
  ## geom_text(data=boundary_summary, aes(x=75, y=0.1, label=shift_text), color='black') + 
  theme(legend.position='none') +
  scale_x_continuous('VOT (ms)') +
  scale_y_continuous('Probability /p/ response') + 
  scale_color_discrete('/b/ mean\nVOT')


```

## Results: category boundaries

```{r boundary-violin-plots, fig.width=6.5, fig.height=4.5}

ggplot(boundaries, aes(y = boundary, x = bvotCond, fill = bvotCond)) +
  geom_violin(color='white',draw_quantiles=c(0.25, 0.5, 0.75), show.legend=FALSE) +
  geom_segment(data = boundaries %>%    # prior boundary
                 summarise(xmin = min(as.numeric(bvotCond))-0.5,
                           xmax = max(as.numeric(bvotCond))+0.5,
                           y = unique(prior_bound)),
               aes(x=xmin, xend=xmax, y=y, yend=y, fill=NA),
               color='black', linetype=2) + 
  geom_segment(aes(x=as.numeric(bvotCond)-.5, # exposure boundaries
                   xend=as.numeric(bvotCond)+.5,
                   y=ideal_boundary,
                   yend=ideal_boundary,
                   color=bvotCond),
               linetype = 2, size = 1,
               data = boundaries %>% group_by(bvotCond, ideal_boundary) %>% summarise()) +
  geom_violin(color='white',draw_quantiles=c(0.25, 0.5, 0.75), show.legend=FALSE) +
  coord_flip() +
  geom_text(data=(boundaries %>% filter(bvotCond==20) %>% head(n=1)),
            aes(y=ideal_boundary, color=bvotCond),
            ## x=3.5, y=41, 
            label='Intended boundary',
            hjust = 0, vjust = 0,
            nudge_x = -0.5, nudge_y = 1) +
  geom_text(data=(boundaries %>% filter(bvotCond==20) %>% head(n=1)),
            aes(y=prior_boundary), color='black',
            ## x=3.5, y=41, 
            label='Typical talker\'s \nboundary',
            hjust = 1, vjust = 0,
            nudge_x = -0.5, nudge_y = -1) +
  theme(legend.position='none') +
  labs(x = 'Condition (Mean /b/ VOT)',
       y = 'Category boundary (ms VOT)')

```

---

## Questions

1. <span class="yes">Is rapid adaptation to an unfamiliar talker __constrained__?</span>
    * __Yes__: Less adaptation to extreme accents
2. Are constraints consistent with listeners starting from a __single set of prior beliefs__?
3. Do these inferred prior beliefs reflect __talker variation__?

# Modeling

## Previous belief updating model

> * Phonetic categories are distributions of cues with unknown mean and variance
> * Assume a __known__ set of prior beliefs
> * Update beliefs with exposure to unfamiliar talker
> * Changes in beliefs predict changes in classification/category boundary

## Inferring prior beliefs

> * Treat prior beliefs as __unknown__
> * Infer set of prior beliefs that best explains adaptation to different accents:
>     * Prior __expected__ mean and variance
>     * __Confidence__ in prior beliefs

---



```{r load-samples}

mod_samples <- readRDS('../nips_2015/data/samples_lapsing.rds')

```

## Questions

1. <span class="yes">Is rapid adaptation to an unfamiliar talker __constrained__?</span>
    * __Yes__: Less adaptation to extreme accents
2. <span class="fragment highlight-red">Are constraints consistent with listeners starting from a __single set of prior beliefs__?</span>
3. Do these inferred prior beliefs reflect __talker variation__?

## Model vs. data: classification

```{r model-vs-class-data, fig.width=8, fig.height=2, out.width='100%'}

samples_to_dists <- function(samples, subjects, 
                             mean_name = 'mu', sd_name = 'sigma') {

  means <- data.frame(t(apply(samples[[mean_name]], 2:3, mean)))
  names(means) <- c('mean_b', 'mean_p')
  sds <- data.frame(t(apply(samples[[sd_name]], 2:3, mean)))
  names(sds) <- c('sd_b', 'sd_p')

  data.frame(subjects, means, sds) %>%
    gather('stat_cat', 'value', mean_b:sd_p) %>%
    separate(stat_cat, c('statistic', 'category'))
  
}

samples_to_class_funs <- function(samples, ...) {
  samples %>%
    samples_to_dists(...) %>%
    spread(statistic, value) %>%
    group_by(subject, bvotCond) %>%
    do(stats_to_lhood(., noise_sd=0)) %>%
    lhood_to_classification %>%
    group_by(bvotCond, vot) %>%
    summarise(prob_p = mean(prob_p)) %>%
    mutate(bvotCondNum = as.numeric(as.character(bvotCond))) %>%
    filter(vot >= bvotCondNum-20,
           vot <= bvotCondNum+60)
}

lapse_rate <- mean(mod_samples$lapse_rate)

mod_class_funs <- mod_samples %>%
  samples_to_class_funs(subjects, mean_name='mu_n', sd_name='sigma_n') %>%
  mutate(prob_p = lapse_rate/2 + (1-lapse_rate) * prob_p)

ggplot(mod_class_funs, aes(x=vot, y=prob_p, color=bvotCond)) +
  geom_line() +
  geom_pointrange(data=data_by_subject, stat='summary', fun.data='mean_cl_boot') +
  facet_grid(.~bvotCond) +
  scale_x_continuous('VOT (ms)') +
  scale_y_continuous('Probability /p/ response') + 
  scale_color_discrete('/b/ mean\nVOT')



```

## Questions

1. <span class="yes">Is rapid adaptation to an unfamiliar talker __constrained__?</span>
    * __Yes__: Less adaptation to extreme accents
2. <span class="yes">Are constraints consistent with listeners starting from a __single set of prior beliefs__?</span>
    * __Yes__: Belief updating model fits classification well
3. <span class="fragment highlight-red">Do these inferred prior beliefs reflect __talker variation__?</span>

----

## Inferred prior beliefs

```{r inferred-prior-vs-kronrod, fig.width=10, fig.height=3.5, out.width='100%'}

samples_to_prior_stats <- function(samples, mean_name='mu_0', sd_name='sigma_0') {
  data.frame(category = c('b', 'p'),
             mean = apply(samples[[mean_name]], 2, mean),
             sd = apply(samples[[sd_name]], 2, mean))
}

mod_prior_lhood <- mod_samples %>%
  samples_to_prior_stats() %>%
  stats_to_lhood(noise_sd = 0, xlim=c(-100,90)) %>%
  mutate(source = "Inferred prior")

supunsup::prior_stats %>%
  filter(source=='goldrick2013') %>%
  group_by(prevoiced, category) %>%
  do({stats_to_lhood(., xlim=c(-100, 90))}) %>%
  spread(prevoiced, lhood) %>%
  mutate(source = "Goldrick et al. (2013)") %>%
  mutate(lhood = `TRUE` * 0.37 + `FALSE` * 0.63) ->
  goldrick_lhood

all_priors <- prior_lhood %>%
  mutate(source = "Kronrod et al. (2012)") %>%
  bind_rows(mod_prior_lhood) %>%
  bind_rows(goldrick_lhood) %>%
  mutate(source = factor(source,
                         levels = c("Inferred prior",
                                    "Kronrod et al. (2012)",
                                    "Goldrick et al. (2013)")))
  

all_priors %>%
  filter(as.numeric(source) < 3) %>%
  ggplot(aes(x=vot, y=lhood, group=paste(category, source), linetype=source)) +
  ## geom_line(aes(linetype='Inferred prior')) +
  ## geom_line(data=prior_lhood, aes(linetype='Kronrod et al. (2012)')) +
  geom_line() + 
  scale_linetype_discrete('Source') +
  scale_x_continuous('VOT (ms)') +
  scale_y_continuous('Likelihood') 

```

## Inferred prior beliefs

```{r inferred-prior-vs-goldrick, fig.width=10, fig.height=3.5, out.width='100%'}

ggplot() +
  ## geom_line(aes(linetype='Inferred prior')) +
  ## geom_line(data=prior_lhood, aes(linetype='Kronrod et al. (2012)')) +
  geom_line(data =all_priors,
            aes(x=vot, y=lhood, group=paste(category, source), linetype=source)) + 
  scale_linetype_discrete('Source') +
  scale_x_continuous('VOT (ms)') +
  scale_y_continuous('Likelihood')
  ## geom_segment(x = -70, xend = -95, y = 0.02, yend = 0.005,
  ##              arrow = arrow(length = unit(0.03, 'npc'))) +
  ## geom_text(x = -68, y=0.02, label = '37% tokens were\nprevoiced',
  ##           hjust = 0)


```

## Questions

1. <span class="yes">Is rapid adaptation to an unfamiliar talker __constrained__?</span>
    * __Yes__: Less adaptation to extreme accents
2. <span class="yes">Are constraints consistent with listeners starting from a __single set of prior beliefs__?</span>
    * __Yes__: Belief updating model fits classification well
3. <span class="yes">Do these inferred prior beliefs reflect __talker variation__?</span>
    * __Yes__(-ish): Prevoicing potentially explains low expected /b/ VOT

# Conclusion

---

## Distributional learning is __constrained__

* Rapid adaptation can't be the whole story to coping with talker variation
* Where do constraints come from?

## The ideal adapter

* Results are consistent with predictions of __ideal adapter__ framework
* Efficient belief updating requires informative prior starting point
* Experience with other talkers can provide this prior

## There are other possible sources of constraints!

* Psychoacoustics
* Own production processes
* etc.

## Future directions

* Ideal adapter predictions depend on __type__ and __amount__ of cross-talker variability.
* (relatively) __weaker constraints__ for more variable contrasts (e.g., fricatives and vowels)
* (relatively) __stronger constraints__ when listeners have more specific expectations (e.g., gender and dialect)

## Mind reading

* Probing listeners' subjective expectations is __hard__.
* Adaptation + belief updating models provide a missing __tool__.
* Bonus: doesn't require __production__ data.

## Thanks!

# Belief updating

---

```{r fitted-parameter-updating}

library(beliefupdatr)
## available from github:
## devtools::install_github('dgrtwo/gganimate')
library(gganimate)

samples_to_nix_params <- function(samples) {
  samples %>%
    samples_to_prior_stats %>%
    transmute(category, mu = mean, sigma2 = sd^2) %>%
    mutate(kappa = mean(samples$kappa_0),
           nu = mean(samples$nu_0))
}

p0 <- samples_to_nix_params(mod_samples) %>%
  group_by(category) %>%
  do(p = {do.call(nix2_params, .)})
  
updated_p <- data %>%
  group_by(bvotCond) %>%
  filter(subject == first(subject)) %>%
  select(vot, trial, bvotCond, trueCat) %>%
  group_by(bvotCond, trueCat) %>%
  summarise(xbar = mean(vot),
            s2 = var(vot)) %>%
  rowwise() %>%
  do(data.frame(., n = seq(0, 220, by=10))) %>%
  left_join(p0, by=c(trueCat='category')) %>%
  mutate(p_updated = list(nix2_update(p=p, xbar=xbar, s2=s2, n=n)))

updated_p_lhoods <- 
  updated_p %>%
  group_by(bvotCond, trueCat, n) %>%
  do({ data_frame(vot = -30:100,
                  lhood = d_nix2_predict(vot, .$p_updated[[1]])) })
  
```


```{r lhood-fcn-update-animation, fig.show='animate', out.width='50%'}

## likelihood curves
ggplot(updated_p_lhoods,
       aes(x=vot, y=lhood, color=bvotCond, linetype=trueCat,
           group=paste(bvotCond, trueCat, n),
           frame = n)) +
  geom_line() -> p

gg_animate(p)

```

```{r class-fcn-update-animation, fig.show='animate', out.width='50%'}

## classification functions
updated_p_lhoods %>%
  spread(trueCat, lhood) %>%
  mutate(respP = p / (b+p)) %>%
  ggplot(aes(x=vot, y=respP, color=bvotCond,
             group=paste(bvotCond, n),
             frame = n)) +
  geom_line() -> p

gg_animate(p)

```



