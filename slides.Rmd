---
author: "Dave F. Kleinschmidt and T. Florian Jaeger"
title: "What do you expect from an unfamiliar talker?"
output: html_document

---


```{r preamble, message = FALSE, warning = FALSE, error = FALSE, results='hide', echo=FALSE}

library(knitr)

opts_chunk$set(dev = c('svg', 'png', 'pdf'),
                      error = FALSE, warning = FALSE, message = FALSE,
                      results = 'hide', echo = FALSE,
                      cache = TRUE)

## FRom the gganimate github readme: a hacked-together gif animation hook:
## https://github.com/dgrtwo/gganimate/blob/master/README.Rmd
library(animation)
ani.options(autobrowse = FALSE, interval = .2)

opts_knit$set(animation.fun = function(x, options, format = "gif") {
  x = c(knitr:::sans_ext(x), knitr:::file_ext(x))
  fig.num = options$fig.num
  format = sub("^[.]", "", format)
  fig.fname = paste0(sub(paste0(fig.num, "$"), "*", x[1]), 
                     ".", x[2])
  mov.fname = paste0(sub(paste0(fig.num, "$"), "", x[1]), ".", 
                     format)

  # order correctly
  figs <- Sys.glob(fig.fname)
  figs <- figs[order(as.numeric(stringr::str_match(figs, paste0("(\\d+)\\.", x[2]))[, 2]))]

  animation::im.convert(figs, output = mov.fname)
  
  sprintf("![%s](%s)", options$label, paste0(opts_knit$get("base.url"), mov.fname))
})


library(dplyr)
library(tidyr)
library(magrittr)
library(ggplot2)
library(assertthat)

theme_set(theme_bw())

## data and helper functions
## devtools::install_github('kleinschmidt/phonetic-sup-unsup')
require(supunsup)

data <- supunsup::supunsup_clean %>%
  filter(supCond == 'unsupervised') %>%
  mutate(trueCat = respCategory,
         subjNum = as.numeric(factor(subject)),
         trueCatNum = as.numeric(trueCat),
         respCatNum = as.numeric(respCat))

data_by_subject <- data %>%
  group_by(subject, bvotCond, vot) %>%
  summarise(prob_p = mean(respP))

# correspondence between subject ids and numbers from model
subjects <-
  data %>%
  mutate(subject_num = as.numeric(factor(subject))) %>%
  group_by(subject, bvotCond, subject_num) %>%
  summarise() %>%
  arrange(subject_num)

```

# Introduction

```{r belief-updating-setup}

# sample a bunch of means and variances
# sample data points from one set of categories
# get log-lhood of each data point under each set of category parameters
# incrementally accumulate log-lhood

# gamma distribution parametrized by mean and sd
rgamma_meansd <- function(n, mean, sd, ...) {
  scale <- sd^2 / mean
  shape <- mean / scale
  rgamma(n, shape=shape, scale=scale, ...)
}

# sample a single prior from a base distribution
r_particle_one <- function(mu0 = c(0, 60),
                             mu_sigma = c(20, 20),
                             sigma0 = c(10, 15),
                             sigma_sigma = c(5, 5)) {
  k <- max(sapply(list(mu0, sigma0, mu_sigma, sigma_sigma), length))
  mu <- rnorm(n=k, mean=mu0, sd=mu_sigma)
  sigma <- rgamma_meansd(n=k, mean=sigma0, sd=sigma_sigma)
  n <- max(sapply(list(mu, sigma), length))
  list(mu=mu, sigma=sigma, theta=rep(1/n, n))
}
r_particle_prior <- function(n, ...) lapply(1:n, function(n, ...) r_particle_one(...), ...)


log_sum_exp <- function(x) log(sum(exp(x - max(x)))) + max(x)

# likelihood of data given particle (a mixture model)
d_particle <- function(x, p, log=FALSE) {
  log_lhood <- log_sum_exp(dnorm(x, mean=p$mu, sd=p$sigma, log=TRUE) + log(p$theta))
  if (log) {
    return(log_lhood)
  } else {
    return(exp(log_lhood))
  }
}

normalize <- function(x) x / sum(x)

# classification function from mixture particle
id_particle <- function(x, p) {
  
  # compute likelihood
  sapply(x, function(xx) normalize(dnorm(xx, mean=p$mu, sd=p$sigma, log=FALSE) * p$theta))

}

set.seed(100)
n_part <- 200
particles <- r_particle_prior(n_part)

lapply(particles, d_particle, x=0, log=TRUE)

#' Re-weight particles based on data
#'
#' @param x Sequence of data to update particles with (in order)
#' @param particles List of particles to update
#' @param d_part Likelihood function (called as d_part(x, p, log=TRUE)).
#'
#' @return A data_frame with columns x, x_idx (data/time index), p (particle),
#'   p_idx (particle index), lhood (log likelihood of data point under particle),
#'   lhood_cumulative (cumulative log likelihood of particle to that point) and
#'   weight (normalized particle weights at current time)
weight_particles <- function(x, particles, d_part) {

  data_frame(x) %>%
    mutate(x_idx = row_number()) %>%
    group_by(x, x_idx) %>%
    do({ data_frame(p=particles) %>% mutate(p_idx = row_number()) }) %>%
    rowwise() %>%
    mutate(lhood = d_part(x, p, log=TRUE)) %>%
    group_by(p_idx) %>%
    arrange(x_idx) %>%
    mutate(lhood_cumulative = cumsum(lhood)) %>%
    group_by(x_idx) %>%
    mutate(weight = exp(lhood_cumulative - log_sum_exp(lhood_cumulative)))

}


plot_particle_updating <- function(x, particles,
                                   x_idx_to_plot_at = round(seq(1, length(x), length.out=11)),
                                   x_to_plot_at = seq(-30, 120),
                                   true_particle = NA) {

  times_to_plot <- seq(1, 200, by=20)

  weighted_particles <-
    weight_particles(x, particles, d_particle) %>%
    ungroup() %>% 
    filter(x_idx %in% x_idx_to_plot_at)

  # data frame with pdf for each particle
  particle_pdfs <- data_frame(p = particles) %>%
    mutate(p_idx = row_number()) %>%
    group_by(p_idx) %>%
    do({ data_frame(x_pdf = x_to_plot_at,
                    particle_lhood = sapply(x_pdf, d_particle, p=.$p[[1]], log=FALSE),
                    particle_lhood_normalized = particle_lhood / max(particle_lhood)
                    )
    }) %>%
    full_join(weighted_particles, by='p_idx')

  # for marginal pdf
  particle_pdfs_marginal <- particle_pdfs %>%
    group_by(x_idx, x_pdf) %>%
    summarise(marginal_lhood = sum(weight * particle_lhood))

  # for carpet plot of data points
  xs_before_xidx <- data_frame(x_idx = x_idx_to_plot_at) %>%
    group_by(x_idx) %>%
    do({ data_frame(x = x[1:.$x_idx]) })

  particle_pdfs %>%
    ggplot() +
    geom_line(aes(x=x_pdf, y=particle_lhood, alpha=weight, group=p_idx, frame=x_idx)) +
    geom_line(data=particle_pdfs_marginal,
              aes(x=x_pdf, y=marginal_lhood, group=x_idx, frame=x_idx),
              color='red') + 
    geom_point(data=xs_before_xidx, aes(x=x, y=0, alpha=1, frame=x_idx), shape='|') + 
    scale_alpha_continuous(range=c(0.00,1)) +
    guides(alpha = FALSE) +
    theme(panel.grid = element_blank(),
          panel.border = element_blank(),
          axis.title.y = element_blank(),
          axis.text.y = element_blank(),
          axis.ticks.y = element_blank(),
          axis.line.y = element_blank()) ->
    p

  # if there's a true particle, add its likelihood to the plot
  if (!is.na(true_particle)) {
    true_lhood <- data_frame(x_pdf = x_to_plot_at,
                             lhood = sapply(x_pdf, d_particle, p=true_particle))
    lhood_range <- range(true_lhood$lhood)
    p <- p + 
      geom_line(data = true_lhood, aes(x=x_pdf, y=lhood), color='blue') +
      coord_cartesian(ylim = lhood_range + diff(lhood_range)*c(-0.02, 0.2))
  }

  return(p)

}

true_particle <- list(mu = c(0, 60),
                      sigma = c(10, 22),
                      theta = c(0.5, 0.5))

# draw samples from the data distribution of a particle
sample_from_particle <- function(n, p) {
  K <- max(sapply(p, length))
  k <- sample(K, size=n, replace=TRUE, prob = rep(p$theta,length.out=K))
  rnorm(n, mean = p$mu[k], sd = p$sigma[k])
}

x <- sample_from_particle(200, true_particle)


weighted_particles <- weight_particles(x, particles, d_particle)


# plot particle weights over data
## weighted_particles %>%
##   ggplot(aes(x=x_idx, y=weight, group=p_idx, color=factor(p_idx))) +
##   geom_line(position='stack') +
##   guides(color = FALSE)

weighted_particles %>%
  ggplot(aes(x=x_idx, y=weight, fill=factor(p_idx))) +
  geom_area() +
  guides(fill = FALSE)


```

```{r belief-updating-animation-flat, dev='png', fig.show='animate', fig.width=8, fig.height=4, dependson='belief-updating-setup'}

t_to_plot_at = c(1:20, seq(30, 100, by=10))
## t_to_plot_at = c(1, 10, 20)

flat_particles <- r_particle_prior(500,
                                   mu0 = c(30, 30),
                                   mu_sigma = 20,
                                   sigma0 = 15,
                                   sigma_sigma = 7)

flat_particles %>%
  plot_particle_updating(x=x, x_idx_to_plot_at = t_to_plot_at,
                         true_particle=true_particle) %>%
  gg_animate()

```

```{r belief-updating-animation-informed, dev='png', fig.show='animate', fig.width=8, fig.height=4, dependson='belief-updating-setup'}


informed_particles <- r_particle_prior(500,
                                       mu0 = c(0, 60),
                                       mu_sigma = c(10, 20),
                                       sigma0 = c(10, 22),
                                       sigma_sigma = c(4, 8))

informed_particles %>%
  plot_particle_updating(x=x, x_idx_to_plot_at = t_to_plot_at,
                         true_particle=true_particle) %>%
  gg_animate()

```

```{r belief-updating-animation-misinformed, dev='png', fig.show='animate', fig.width=8, fig.height=4, dependson='belief-updating-setup'}


misinformed_particles <- r_particle_prior(500,
                                          mu0 = c(20, 80),
                                          mu_sigma = c(10, 10),
                                          sigma0 = c(10, 22),
                                          sigma_sigma = c(4, 8))

misinformed_particles %>%
  plot_particle_updating(x=x, particles=.,
                         x_idx_to_plot_at = t_to_plot_at,
                         true_particle=true_particle) %>%
  gg_animate()

```

# Methods

```{r distributions, fig.width=8, fig.height=2}

## prior_stats <- data.frame(category=factor(c('b', 'p')),
##                           mean = c(0, 60),
##                           sd = sqrt(c(14, 254)))

prior_stats <- supunsup::prior_stats %>%
  filter(source == 'kronrod2012')

exposure_stats <- data %>%
  group_by(bvotCond, category=trueCat) %>%
  summarise(mean=mean(vot), sd=sd(vot))

sd_noise = sqrt(82)

stats_to_lhood <- function(stats, noise_sd=sd_noise) {
  stats %>%
    group_by(category, mean, sd) %>%
    do(data.frame(vot=seq(-30, 90, 0.5))) %>%
    ungroup() %>%
    mutate(lhood = dnorm(vot, mean, sqrt(sd^2 + noise_sd^2))) %>%
    select(-mean, -sd)
}

exposure_lhood <- exposure_stats %>%
  group_by(bvotCond) %>%
  do(stats_to_lhood(., sd_noise))

prior_lhood <- prior_stats %>% stats_to_lhood(sd_noise)

data %>%
  group_by(bvotCond, vot) %>%
  filter(subject == first(subject)) %>%
  tally() %>%
  ggplot(aes(x=vot)) +
  geom_bar(stat='identity', aes(y=n, fill=bvotCond)) +
  geom_line(data=prior_lhood, aes(y=lhood*1600, group=category),
            color="black", linetype=2) +
  geom_text(data=data.frame(bvotCond=-10), x = 10, y = 60,
            label = 'Typical Talker',
            color='black', hjust=0, vjust=0.3, size=3) +
  geom_text(data=data.frame(bvotCond=-10), x = 40, y = 50,
            label = 'Exposure\nTalker',
            color=hcl(h=15, c=100, l=65), hjust=0, vjust=0.8, size=3,
            lineheight=1) + 
  facet_grid(.~bvotCond) +
  scale_x_continuous('VOT (ms)') +
  scale_y_continuous('Frequency') +
  scale_fill_discrete('/b/ mean\nVOT') +
  theme(legend.position='none')

```

# Results

```{r class-fcns, fig.width=8, fig.height=2}

lhood_to_classification <- function(lhood) {
  lhood %>%
    spread(category, lhood) %>%
    mutate(prob_p = p / (p+b))
}

perfect_learning <- exposure_stats %>%
  group_by(bvotCond) %>%
  do(stats_to_lhood(.)) %>%
  lhood_to_classification

no_learning <- prior_stats %>%
  stats_to_lhood %>%
  lhood_to_classification

prior_bound <- no_learning %>%
  arrange(abs(prob_p - 0.5)) %>%
  filter(row_number() ==1) %$%
  vot


boundaries <- data %>%
  group_by(bvotCond, subject) %>%
  do({ glm(respP ~ vot, family='binomial', data=.) %>%
         broom::tidy() %>%
         select(term, estimate)
  }) %>%
  ungroup() %>%
  spread(term, estimate) %>%
  mutate(boundary = -`(Intercept)` / vot,
         ideal_boundary = as.numeric(as.character(bvotCond)) + 20,
         prior_boundary = prior_bound,
         prop_shift = (boundary-prior_boundary)/(ideal_boundary-prior_boundary))

boundary_summary <- boundaries %>%
  group_by(bvotCond) %>%
  summarise(median_shift_perc = round(100*median(prop_shift)),
            shift_text = paste(median_shift_perc, '%', sep='')) %>%
  filter(bvotCond != 0)                 # basically no shift possible


ggplot(data, aes(x=vot, y=respP, color=bvotCond)) +
  geom_line(aes(group=subject), stat='smooth', 
            method='glm', method.args=list(family='binomial'),
            alpha=0.2) +
  facet_grid(.~bvotCond) +
  geom_line(data=perfect_learning, aes(y=prob_p), group=1, linetype=2, size=1) +
  geom_line(data=no_learning, aes(y=prob_p), group=1, linetype=2, color='black') +
  geom_text(data=data.frame(bvotCond=-10),
            x = 30, y = 0, label = 'Typical\ntalker',
            size = 3.5, hjust=0, vjust = 0, color='black',
            lineheight=1) + 
  geom_text(data=data.frame(bvotCond=-10),
            x = 12, y = 1, label = 'Expo-\nsure',
            size = 3.5, hjust=1, vjust=1, color=hcl(15, c=100, l=65),
            lineheight=1, fontface='bold') + 
  geom_text(data=data.frame(bvotCond=-10),
            x = 90, y = 0.75, label = 'Actual\nlisteners',
            size = 3.5, hjust=1, vjust=1, color=hcl(15, c=100, l=65),
            lineheight=1) + 
  ## geom_text(data=boundary_summary, aes(x=75, y=0.1, label=shift_text), color='black') + 
  theme(legend.position='none') +
  scale_x_continuous('VOT (ms)') +
  scale_y_continuous('Probability /p/ response') + 
  scale_color_discrete('/b/ mean\nVOT')


```

# Modeling

```{r load-samples}

mod_samples <- readRDS('../nips_2015/data/samples_lapsing.rds')

```

```{r model-vs-class-data, fig.width=8, fig.height=2}

samples_to_dists <- function(samples, subjects, 
                             mean_name = 'mu', sd_name = 'sigma') {

  means <- data.frame(t(apply(samples[[mean_name]], 2:3, mean)))
  names(means) <- c('mean_b', 'mean_p')
  sds <- data.frame(t(apply(samples[[sd_name]], 2:3, mean)))
  names(sds) <- c('sd_b', 'sd_p')

  data.frame(subjects, means, sds) %>%
    gather('stat_cat', 'value', mean_b:sd_p) %>%
    separate(stat_cat, c('statistic', 'category'))
  
}

samples_to_class_funs <- function(samples, ...) {
  samples %>%
    samples_to_dists(...) %>%
    spread(statistic, value) %>%
    group_by(subject, bvotCond) %>%
    do(stats_to_lhood(., noise_sd=0)) %>%
    lhood_to_classification %>%
    group_by(bvotCond, vot) %>%
    summarise(prob_p = mean(prob_p)) %>%
    mutate(bvotCondNum = as.numeric(as.character(bvotCond))) %>%
    filter(vot >= bvotCondNum-20,
           vot <= bvotCondNum+60)
}

lapse_rate <- mean(mod_samples$lapse_rate)

mod_class_funs <- mod_samples %>%
  samples_to_class_funs(subjects, mean_name='mu_n', sd_name='sigma_n') %>%
  mutate(prob_p = lapse_rate/2 + (1-lapse_rate) * prob_p)

ggplot(mod_class_funs, aes(x=vot, y=prob_p, color=bvotCond)) +
  geom_line() +
  geom_pointrange(data=data_by_subject, stat='summary', fun.data='mean_cl_boot') +
  facet_grid(.~bvotCond) +
  scale_x_continuous('VOT (ms)') +
  scale_y_continuous('Probability /p/ response') + 
  scale_color_discrete('/b/ mean\nVOT')



```

```{r inferred-prior-vs-kronrod, fig.width=4, fig.height=3}


samples_to_prior_stats <- function(samples, mean_name='mu_0', sd_name='sigma_0') {
  data.frame(category = c('b', 'p'),
             mean = apply(samples[[mean_name]], 2, mean),
             sd = apply(samples[[sd_name]], 2, mean))
}

mod_prior_lhood <- mod_samples %>%
  samples_to_prior_stats %>%
  stats_to_lhood(noise_sd = 0)

ggplot(mod_prior_lhood, aes(x=vot, y=lhood, group=category)) +
  geom_line(aes(linetype='Inferred\nprior')) +
  geom_line(data=prior_lhood, aes(linetype='Kronrod et\nal. (2012)')) +
  scale_linetype_discrete('Source') +
  scale_x_continuous('VOT (ms)') +
  scale_y_continuous('Likelihood')


```

```{r fitted-parameter-updating}

library(beliefupdatr)
## available from github:
## devtools::install_github('dgrtwo/gganimate')
library(gganimate)

samples_to_nix_params <- function(samples) {
  samples %>%
    samples_to_prior_stats %>%
    transmute(category, mu = mean, sigma2 = sd^2) %>%
    mutate(kappa = mean(samples$kappa_0),
           nu = mean(samples$nu_0))
}

p0 <- samples_to_nix_params(mod_samples) %>%
  group_by(category) %>%
  do(p = {do.call(nix2_params, .)})
  
updated_p <- data %>%
  group_by(bvotCond) %>%
  filter(subject == first(subject)) %>%
  select(vot, trial, bvotCond, trueCat) %>%
  group_by(bvotCond, trueCat) %>%
  summarise(xbar = mean(vot),
            s2 = var(vot)) %>%
  rowwise() %>%
  do(data.frame(., n = seq(0, 220, by=10))) %>%
  left_join(p0, by=c(trueCat='category')) %>%
  mutate(p_updated = list(nix2_update(p=p, xbar=xbar, s2=s2, n=n)))

updated_p_lhoods <- 
  updated_p %>%
  group_by(bvotCond, trueCat, n) %>%
  do({ data_frame(vot = -30:100,
                  lhood = d_nix2_predict(vot, .$p_updated[[1]])) })
  
```

```{r lhood-fcn-update-animation, fig.retina=2, dev='png', fig.show='animate'}

## likelihood curves
ggplot(updated_p_lhoods,
       aes(x=vot, y=lhood, color=bvotCond, linetype=trueCat,
           group=paste(bvotCond, trueCat, n),
           frame = n)) +
  geom_line() -> p

gg_animate(p)

```


```{r class-fcn-update-animation, fig.retina=2, dev='png', fig.show='animate'}

## classification functions
updated_p_lhoods %>%
  spread(trueCat, lhood) %>%
  mutate(respP = p / (b+p)) %>%
  ggplot(aes(x=vot, y=respP, color=bvotCond,
             group=paste(bvotCond, n),
             frame = n)) +
  geom_line() -> p

gg_animate(p)

```





